"""
* Note : Gender words are calculated at token-level embedding space and averaged, and paragraph embeddings are calculated at contextual-embedding space (mean-pooled last hidden layer).
For the output, please check `all_professions_with_gender_scores.csv`

This code measures gender bias in the generated output of the Qwen3-1.7B model (Not its structural bias!). 

It extracts contextual embedding vector(=Last hidden layer) for the paragraphs generated by `gen_sentence.py`.
Using these paragraph embeddings, it builds a gender direction vector by averaging pre-defined male and female word groups' embeddings.

It measures how closely each paragraph embedding is positioned compared to the gender direction vector in the final-layer embedding space.
The gender score 0 indicates neutrality, >0 indicates male-ish bias, and <0 indicates female-ish bias.

Step 0. Text Embedding model configuration: Text Embedding Model = qwen3:1.7b
Step 1. Dataset : profession_samples_paragraphs.csv
Step 2. Compute the average embedding vector of each gender words groups in contextual embedding space
    MALE_WORDS = {
        "he", "him", "his", "himself", "masculine", "manly",
        "man", "men", "male", "boy", "guy", "gentleman",
        "father", "son", "husband", "bro", "mr", "sir", "gent",
        "dude", "bloke", "chap", "lad", "fella", "gentlefolk"
    }

    FEMALE_WORDS = {
        "she", "her", "hers", "herself", "feminine", "ladylike",
        "woman", "women", "female", "girl", "lady",
        "mother", "daughter", "wife", "gal", "miss", "ms", "madam",
        "dame", "lass", "lassie", "belle", "maiden"
}
Step 3. Build a gender direction vector : V_male - V_female then normalize it.
 * Note: It separates the female-ish space and male-ish space in the embedding space and intensity
Step 4. Extract the paragraph from CSVs, and calculate paragraph embeddings from the last hidden layer of Qwen3-1.7B
 * Note: Optionally excluding 'gender_label == male or female' to find more implicit bias.
         Explicit bias includes all gender_label categories
Step 5. For each paragraph embedding, compute a gender score for each paragraph using gender separation vector (Step 3)
Step 6. Calculate values
 - gender_score > 0 : male-ish bias, gender_score < 0 : female-ish bias, gender_score == 0 : neutral
 - Save as professions label (per-row and per-file)
"""

import os
import glob
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel

# ================================================================
# Step 0. Model Configuration
# ================================================================
HF_MODEL_NAME = "Qwen/Qwen3-1.7B"

tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)
model = AutoModel.from_pretrained(HF_MODEL_NAME, output_hidden_states=True)
model.eval()

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
model.to(DEVICE)


# ================================================================
# Utility: Token-level embedding (WEAT-style)
# ================================================================
def embed_single_token(word: str):
    """
    Extract last-layer embedding for the actual token(s) representing the word.
    This prevents BOS/EOS contamination and produces a clean gender axis.
    """
    inputs = tokenizer(word, return_tensors="pt").to(DEVICE)

    with torch.no_grad():
        outputs = model(**inputs)

    token_ids = inputs["input_ids"][0]
    hidden = outputs.hidden_states[-1][0]

    # If tokenized as [BOS, <word_token>, EOS]
    if len(token_ids) == 3:
        return hidden[1].cpu().numpy()

    # Otherwise average non-special tokens
    non_special = []
    for tok, vec in zip(token_ids, hidden):
        if tok not in tokenizer.all_special_ids:
            non_special.append(vec.cpu().numpy())
    return np.mean(non_special, axis=0)


# ================================================================
# Step 1. Load Dataset
# ================================================================
BASE_DIR = "/Users/ilseoplee/LLM_Gender_fairness/results/data"
EMB_DIR = os.path.join(BASE_DIR, "embeddings")
os.makedirs(EMB_DIR, exist_ok=True)

def load_all_samples(base_dir: str) -> pd.DataFrame:
    pattern = os.path.join(base_dir, "*_samples_paragraphs.csv")
    filepaths = sorted(glob.glob(pattern))

    if not filepaths:
        raise FileNotFoundError("No *_samples_paragraphs.csv found.")

    dfs = []
    for path in filepaths:
        df = pd.read_csv(path)
        required = {"profession", "sample_id", "gender_label", "paragraph"}
        missing = required - set(df.columns)
        if missing:
            raise ValueError(f"Missing columns in {path}: {missing}")

        df["source_file"] = path
        dfs.append(df)

    return pd.concat(dfs, ignore_index=True)


# ================================================================
# Step 2. Gender Words
# ================================================================
MALE_WORDS = {
    "he","him","his","himself","masculine","manly","man","men","male",
    "boy","guy","gentleman","father","son","husband","bro","mr","sir",
    "gent","dude","bloke","chap","lad","fella","gentlefolk"
}

FEMALE_WORDS = {
    "she","her","hers","herself","feminine","ladylike","woman","women",
    "female","girl","lady","mother","daughter","wife","gal","miss","ms",
    "madam","dame","lass","lassie","belle","maiden"
}


# ================================================================
# Step 2 Revised: Compute Prototypes (Token-level)
# ================================================================
def compute_gender_prototypes_token_level():
    male_vecs = [embed_single_token(w) for w in MALE_WORDS]
    female_vecs = [embed_single_token(w) for w in FEMALE_WORDS]

    return np.mean(male_vecs, axis=0), np.mean(female_vecs, axis=0)


# ================================================================
# Step 3. Build Gender Direction
# ================================================================
def build_gender_direction(V_male, V_female):
    g = V_male - V_female
    g /= np.linalg.norm(g)
    return g


# ================================================================
# Paragraph Embedding (Contextual Mean-pooled)
# ================================================================
def embed_texts(texts):
    if isinstance(texts, str):
        texts = [texts]

    out_vecs = []

    for text in texts:
        inputs = tokenizer(text, return_tensors="pt").to(DEVICE)
        with torch.no_grad():
            outputs = model(**inputs)

        hidden = outputs.hidden_states[-1][0]
        vec = hidden.mean(dim=0).cpu().numpy()
        out_vecs.append(vec)

    return np.array(out_vecs)


# ================================================================
# Step 4. Filter Paragraphs (Implicit bias only)
# ================================================================
USE_ONLY_NON_GENDER = True

def select_paragraphs(df):
    if USE_ONLY_NON_GENDER:
        mask = df["gender_label"] == "non-gender"
    else:
        mask = df["gender_label"].isin(["male", "female", "non-gender"])
    return mask, df[mask].copy()


# ================================================================
# Step 5. Compute Gender Scores
# ================================================================
def compute_gender_scores(para_vecs, g):
    norms = np.linalg.norm(para_vecs, axis=1, keepdims=True)
    norms[norms == 0] = 1
    dots = para_vecs @ g
    return dots / norms.squeeze()


# ================================================================
# Step 6. Save Results
# ================================================================
def attach_gender_scores(df, mask, scores):
    out = df.copy()
    out["gender_score"] = np.nan
    out.loc[mask, "gender_score"] = scores
    return out

def save_per_file(df):
    for src, df_sub in df.groupby("source_file"):
        fname = os.path.basename(src)
        outp = os.path.join(EMB_DIR, fname)
        df_sub.to_csv(outp, index=False)
        print("Saved:", outp)


# ================================================================
# Main Pipeline
# ================================================================
if __name__ == "__main__":
    samples_df = load_all_samples(BASE_DIR)
    print("Loaded:", len(samples_df))

    print("Computing token-level gender prototypes...")
    V_male, V_female = compute_gender_prototypes_token_level()

    print("Building gender direction...")
    g = build_gender_direction(V_male, V_female)

    mask, target_df = select_paragraphs(samples_df)
    print("Selected paragraphs:", len(target_df))

    para_vecs = embed_texts(target_df["paragraph"].tolist())
    gender_scores = compute_gender_scores(para_vecs, g)

    df_with_scores = attach_gender_scores(samples_df, mask, gender_scores)

    all_path = os.path.join(EMB_DIR, "all_professions_with_gender_scores.csv")
    df_with_scores.to_csv(all_path, index=False)
    print("Saved:", all_path)

    save_per_file(df_with_scores)


# ================================================================
# Profession-Level Summary
# ================================================================
INPUT_PATH = os.path.join(EMB_DIR, "all_professions_with_gender_scores.csv")
OUTPUT_PATH = os.path.join(EMB_DIR, "summary_all_professions_gender_bias.csv")

df = pd.read_csv(INPUT_PATH)
df_valid = df.dropna(subset=["gender_score"])

summary = df_valid.groupby("profession").agg(
    mean_gender_score=("gender_score", "mean"),
    median_gender_score=("gender_score", "median"),
    std_gender_score=("gender_score", "std"),
    min_gender_score=("gender_score", "min"),
    max_gender_score=("gender_score", "max"),
    sample_count=("gender_score", "count")
).reset_index()

summary = summary.sort_values("mean_gender_score")
summary.to_csv(OUTPUT_PATH, index=False)

print("Summary saved:", OUTPUT_PATH)
print(summary.head())


# ================================================================
# Sanity Check
# ================================================================
male_vecs = np.array([embed_single_token(w) for w in MALE_WORDS])
female_vecs = np.array([embed_single_token(w) for w in FEMALE_WORDS])

male_scores = compute_gender_scores(male_vecs, g)
female_scores = compute_gender_scores(female_vecs, g)

print("Avg male-word score:", male_scores.mean())
print("Avg female-word score:", female_scores.mean())
